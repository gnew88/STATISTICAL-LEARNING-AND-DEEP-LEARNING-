{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 統計學習與深度學習 Homework 2\n",
    "### 財金四 翁如萱 b07703093\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一題 [Data Preprocessing]\n",
    "本題目的在於進行資料前處理，而需要完成的事項如下:\n",
    "- 將標籤 '>50K' 與 '<=50K' 轉換為 1, 0\n",
    "- 移除含有缺值的觀測值\n",
    "- 將所有數值欄位進行標準化, 另外測試資料特徵是需要使用到訓練資料來進行標準化的\n",
    "- 類別欄位使用 1-of-k encoding, 且僅保留在 train 當中出現不小於 10 次的特徵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```使用套件```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from warnings import filterwarnings \n",
    "\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```匯入資料```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import adult_m50k.pickle\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset from the url which is given in the description\n",
    "# remove the first row in adult.test\n",
    "train = pd.read_csv('adult/adult.data', header = None, skipinitialspace = True)\n",
    "test = pd.read_csv('adult/adult.test', header = None, skipinitialspace = True)\n",
    "\n",
    "# add the column to identify whether it belongs to train data or not.\n",
    "train['train'] = 1\n",
    "test['train'] = 0\n",
    "\n",
    "# concat train and test data vertically\n",
    "all_data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48842 entries, 0 to 16280\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       48842 non-null  int64 \n",
      " 1   1       48842 non-null  object\n",
      " 2   2       48842 non-null  int64 \n",
      " 3   3       48842 non-null  object\n",
      " 4   4       48842 non-null  int64 \n",
      " 5   5       48842 non-null  object\n",
      " 6   6       48842 non-null  object\n",
      " 7   7       48842 non-null  object\n",
      " 8   8       48842 non-null  object\n",
      " 9   9       48842 non-null  object\n",
      " 10  10      48842 non-null  int64 \n",
      " 11  11      48842 non-null  int64 \n",
      " 12  12      48842 non-null  int64 \n",
      " 13  13      48842 non-null  object\n",
      " 14  14      48842 non-null  object\n",
      " 15  train   48842 non-null  int64 \n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# print information about dataframe\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns name\n",
    "all_data.columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', \n",
    "                    'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
    "                    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income', 'train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```移除所有含有缺值的資料```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with '?'\n",
    "all_data = all_data[(all_data != '?').all(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```將 '>50K'與'<=50k'轉換為 1, 0```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform '>50k' to 1 and '<=50k' to 0\n",
    "all_data['income'] = all_data['income'].apply(lambda x : 0 if x.find('<=') != -1 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```進行 1-of-K encoding```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split columns into categorical columns, numerical columns, and other columns (train, income)\n",
    "all_col = all_data.columns\n",
    "cat_col = ['relationship', 'race', 'gender', 'occupation', 'education',\n",
    "           'native-country', 'workclass', 'marital-status']\n",
    "num_col = ['capital-loss', 'hours-per-week', 'capital-gain', 'educational-num', 'age', 'fnlwgt']\n",
    "other_col = ['income', 'train']\n",
    "\n",
    "# rearrange dataframe\n",
    "all_data = all_data[num_col + other_col + cat_col]\n",
    "# implement 1-of-k encoding\n",
    "all_data = pd.get_dummies(data = all_data, columns = cat_col, prefix = cat_col, prefix_sep = '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['occupation_Armed-Forces', 'native-country_Holand-Netherlands'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# all of the 1-of-k columns are placed behind the 'train' column\n",
    "# get the index of 'train' column\n",
    "train_idx = all_data.columns.get_loc('train')\n",
    "\n",
    "# we only consider the features whose size are not less than 10 in train data\n",
    "train = all_data.loc[(all_data['train'] == 1)]\n",
    "\n",
    "# check for the columns whose sum (size) are less than 10\n",
    "# so as not to remove the num_col\n",
    "print(all_data.columns[train.sum() < 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave the qualified columns\n",
    "all_data = all_data[all_data.columns[train.sum() >= 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```數值欄位標準化```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numerical columns from train data\n",
    "num_train = train.iloc[:, :train_idx - 1]\n",
    "\n",
    "# compute the mean and std from num_train\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(num_train)\n",
    "\n",
    "# standardize \n",
    "all_data.iloc[:, :train_idx - 1] = scaler.transform(all_data.iloc[:, :train_idx - 1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```建立字典```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test data\n",
    "train = all_data.loc[all_data['train'] == 1]\n",
    "test = all_data.loc[all_data['train'] == 0]\n",
    "\n",
    "# x_train, y_train\n",
    "x_train = train.drop(['income', 'train'], axis = 1).to_numpy()\n",
    "y_train = train['income'].to_numpy()\n",
    "\n",
    "# x_test, y_test\n",
    "x_test = test.drop(['income', 'train'], axis = 1).to_numpy()\n",
    "y_test = test['income'].to_numpy()\n",
    "\n",
    "# column_name\n",
    "all_col = list(all_data.columns)\n",
    "del all_col[train_idx - 1 : train_idx + 1] # remove train and income\n",
    "columnname = all_col\n",
    "\n",
    "# num_col \n",
    "num_col = num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictinary named adult50k\n",
    "adult50k = {'x_train':x_train, 'y_train':y_train, \n",
    "            'x_test':x_test, 'y_test': y_test,\n",
    "            'columnname': columnname, 'num_col':num_col}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```比較 adult50kp 與 adult50k```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train match!\n",
      "x_test match!\n",
      "y_train match!\n",
      "y_test match!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "elems = ['x_train', 'x_test', 'y_train', 'y_test']\n",
    "\n",
    "for aelem in elems:\n",
    "    cnomatch = np.sum(adult50kp[aelem] != adult50k[aelem])\n",
    "    if cnomatch == 0:\n",
    "        print(aelem, \"match!\")\n",
    "    else:\n",
    "        print(aelem, \"%d elements no match!\" % cnomatch)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```處理步驟```\n",
    "- 匯入資料\n",
    "\n",
    "  * 先至題目所給定的網址下載資料集, 接著移除 adult.test 的第一列不重要資訊, 以方便處理\n",
    "  * 匯入資料以後, 新增欄位 'train' 以方便後面辨識是屬於 train data 還是 test data\n",
    "  * 將 train 和 test 合併以後, 根據網站上提供的資料說明, 重新命名欄位名稱\n",
    " \n",
    " \n",
    "- 移除所有含有缺值的資料\n",
    "\n",
    "  * 根據 adult.names 得知, 缺漏值將紀錄 ?, 故移除所有含有 ? 的觀測值\n",
    "\n",
    "\n",
    "- 將標籤欄位轉為 0, 1\n",
    "\n",
    "  * 觀察資料以後發現標籤的值不是只有 '> 50K' 與 '<= 50K' 兩個選項, 因此以含有 '>' 或是 '<=' 符號作為處理準則\n",
    "  \n",
    "  \n",
    "- 進行 1-of-k-encoding\n",
    "\n",
    "  * 將所有類別欄位進行 1-of-k-encoding\n",
    "  * 出現不到 10 次的意思代表著該欄位之數值總和 < 10 (因為類別欄位為0, 1 變數)。根據這項性質取出 train data 當中總和小於 10 的欄位, 確認這些欄位都是類別欄位\n",
    "  * 確認完畢以後, 選取其他大於等於 10 的欄位\n",
    "  \n",
    "  \n",
    "- 數值欄位標準化\n",
    "\n",
    "  * 由於是以訓練資料作為標準化的基準, 所以先取出 train 的數值欄位資料, 接著透過 fit 計算其平均值與變異數\n",
    "  * 將結果套用於整份資料的數值欄位。\n",
    "  \n",
    "  \n",
    "- 建立字典\n",
    "\n",
    "- 確認結果之正確性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二題 [ROC and AUC]\n",
    "利用題目所提供的程式碼得到 ypredprob 以後, 利用其與 adult50kp['y_test'] 繪製 ROC Curve。最後計算此 ROC Curve 的 AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```範例程式碼```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.848406\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load dataset\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "#train prediction model    \n",
    "c = 0.3\n",
    "lr2 = LogisticRegression(solver = 'lbfgs', C= c, max_iter = 1000)\n",
    "lr2.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "#make prediction\n",
    "ypred = lr2.predict(adult50kp['x_test'])\n",
    "ypredprob = lr2.predict_proba(adult50kp['x_test'])\n",
    "#compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred)\n",
    "accuracy_sk = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy_sk)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```繪製 ROC```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value of FPR and TPR under the given value of threshold\n",
    "def get_fpr_tpr(y_actual, y_pred, threshold):\n",
    "    # calculate tp, tn, fp, fn\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i] >= threshold):\n",
    "            if(y_actual[i] == 1):\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if(y_actual[i] == 0):\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    \n",
    "    # calculate fpr and tpr\n",
    "    fpr = fp / (tn + fp)\n",
    "    tpr = tp / (tp + fn)\n",
    "    \n",
    "    return fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "[[0.99710828 0.00289172]\n",
      " [0.87750542 0.12249458]\n",
      " [0.61859624 0.38140376]\n",
      " ...\n",
      " [0.30267414 0.69732586]\n",
      " [0.71883564 0.28116436]\n",
      " [0.20393821 0.79606179]]\n"
     ]
    }
   ],
   "source": [
    "# compare ypred and ypredprob\n",
    "print(ypred)\n",
    "print(ypredprob) # col1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate FPR, TPR under different threshold\n",
    "threshold_list = np.arange(0, 1.025, 0.025) # [0, 0.025, ..., 1]\n",
    "fpr_list = []\n",
    "tpr_list = []\n",
    "\n",
    "y_actual = adult50kp['y_test']\n",
    "y_pred = ypredprob[:, 1]\n",
    "for threshold in threshold_list:\n",
    "    fpr, tpr = get_fpr_tpr(y_actual, y_pred, threshold)\n",
    "    fpr_list.append(fpr)\n",
    "    tpr_list.append(tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```繪製 ROC 曲線```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.plot(fpr_list,tpr_list)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```計算 AUC```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9027873762847355\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auc = 0\n",
    "\n",
    "for idx in range(1, len(tpr_list)):\n",
    "    auc += 0.5 * (tpr_list[idx] + tpr_list[idx - 1]) * (fpr_list[idx - 1] - fpr_list[idx])\n",
    "    \n",
    "print(f\"AUC = {auc}\")    \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```處理步驟```\n",
    "\n",
    "- 設計一個可以計算在不同門檻之下的 FPR, TPR 的函式\n",
    "\n",
    "    * 先計算 fn, tn, fp, tp, 接著求得 fpr, tpr 以後回傳\n",
    "\n",
    "\n",
    "- 確定 y_pred, y_actual\n",
    "    \n",
    "    * 觀察 ypredprob 可發現每筆資料都有兩個機率值, 且此二機率值和為 1\n",
    "    * 將 adult50kp['y_test'] 與 ypredprob 進行比較, 可發現取用 ypredprob 的第 2 欄 (col1) 較能吻合。\n",
    "\n",
    "\n",
    "- 在不同門檻之下計算 fpr, tpr\n",
    "    * 門檻設定為 1 ~ 0 之間, 而間距則是 0.025\n",
    "    * 紀錄每個門檻之下的 fpr, tpr\n",
    "    \n",
    "    \n",
    "- 繪製 ROC Curve\n",
    "    * 利用 fpr_list, tpr_list 畫圖\n",
    "\n",
    "\n",
    "- 計算 AUC\n",
    "    * 將 auc 切割許多梯形, 並進行面積加總"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 第三題 [Logistic Regression with L2 Regularization]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1\n",
    "本題的目的在於推導出 $E(w) = \\frac{1}{2} w^T \\Lambda w - \\sum_{i=1}^n [ t_i \\ln y_i  + (1 - t_i) \\ln (1 - y_i)]$ 的梯度 (gradient) 以及海森矩陣 (hessian matrix)\n",
    "\n",
    "- Gradient:\n",
    "\n",
    "$\\nabla E(w) = \\Lambda w + \\sum_{i=1}^n(y_i - t_i)x_i = \\Lambda w + X(y-t)$\n",
    "\n",
    "- Hessian Matrix\n",
    "$H = \\nabla \\nabla E(w) = \\sum_{i=1}^ny_i(1-y_i)x_ix_i^T+ \\Lambda = X^TRX + \\Lambda$, 其中 $R$ 是一個對角矩陣 (diagonal matrix), 而 $R_{nn} = y_i(1-y_i)$\n",
    "\n",
    "事實上新的 $E(w)$ 原則上和投影片的 $E(w)$相同, 兩者的差異只有 regularized term 以及 notation, 故僅須修正 regularized term 的偏微分計算。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2\n",
    "本題主要目的為建立一個 logistic 模型, 並且在不同的 case 之下訓練模型, 最後展示參數權重以及準確度 (accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```匯入資料```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import adult_m50k.pickle\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```建立 lambda vector```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lambda_vec\n",
    "def create_lambda_vec(num_w, bin_w, add_intercept = True):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    num_w: the regularization coefficient for numerical features\n",
    "    bin_w: the regularization coefficient for binary features\n",
    "    add_intercept: whether to add intercept in the model\n",
    "    \n",
    "    Output:\n",
    "    lambda_vec: The output format is [lam_1, lam_2, ..., lam_D]. lam_k is the regularization coefficient\n",
    "    for w_k, and lam_D only exists when add_intercept = True; moreover, it will be set to 0.\n",
    "    \"\"\"\n",
    "    # get the index of numerical columns and binary columns respectively\n",
    "    all_col_name = adult50kp['columnname']\n",
    "    num_col_name = adult50kp['num_col']\n",
    "    num_col_idx = np.where(np.isin(all_col_name, num_col_name))\n",
    "    bin_col_idx = np.where(~np.isin(all_col_name, num_col_name))\n",
    "    \n",
    "    # create lambda_vec\n",
    "    features_cnt = len(all_col_name)\n",
    "    lambda_vec = np.full([1, features_cnt + add_intercept], 0.)[0]\n",
    "    for idx in range(features_cnt):\n",
    "        lambda_vec[idx] = num_w if np.isin(idx, num_col_idx) else bin_w\n",
    "    \n",
    "    return lambda_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```建立模型```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2():\n",
    "    def __init__(self, reg_vec, max_iter = 100, tol = 1e-5, add_intercept = True):\n",
    "        \"\"\"\n",
    "        reg_vec: the regularization coefficient vector\n",
    "        max_iter: maximum number of iteration to run for the Newton method\n",
    "        tol: tolerance for the objective function\n",
    "        add_intercept: whether to add intercept (a column of ones) at last column of the feature matrix\n",
    "        \"\"\"\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "\n",
    "    def fit(self, x, y, verbal = False):        \n",
    "        \n",
    "        # calculate the error function\n",
    "        def error_function(w):\n",
    "            y = 1 / (1 + np.exp(-x @ w))\n",
    "            error = 0.5 * w.T @ Lambda_matrix @ w - np.sum(np.log(y) * t + np.log(1 - y) * (1 - t))\n",
    "            return error[0][0]\n",
    "            \n",
    "        # reshape y to column vector, and then rename it\n",
    "        t = y.copy().reshape(-1, 1)\n",
    "        \n",
    "        # add intercept to x if add_intercept = True \n",
    "        if(self.add_intercept):\n",
    "            intercept = np.ones((x.shape[0], 1))\n",
    "            x = np.concatenate((x, intercept), axis = 1)\n",
    "       \n",
    "        # whether the length of lambda_vec matches the number of columns of x\n",
    "        # create the diagonal matrix \n",
    "        if(len(self.reg_vec) != x.shape[1]):\n",
    "            raise ValueError('The length of lambda_vec should match the number of columns of x')\n",
    "        else:\n",
    "            Lambda_matrix = np.eye(len(self.reg_vec)) # the diagonal matrix that have lambda_k at Lambda_{kk} \n",
    "            for idx in range(len(self.reg_vec)):\n",
    "                Lambda_matrix[idx][idx] = self.reg_vec[idx]\n",
    "        \n",
    "        # initialize vector of w by using the closed-form solution of ridge regression\n",
    "        b = self.reg_vec.mean() # b is the mean of lambda (including the regularization coef. for intercept)\n",
    "        I = np.eye(len(self.reg_vec))\n",
    "        w = np.linalg.inv(x.T @ x + b * I) @ x.T @ t\n",
    "        \n",
    "        # start to optimize by Newton-Raphson optimization\n",
    "        error = []\n",
    "        w_list = []\n",
    "        \n",
    "        last_error = error_function(w)\n",
    "        error.append(last_error)\n",
    "        w_list.append(w)\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            # calculate gradient and hessian matrix\n",
    "            y =  1 / (1 + np.exp(-x @ w))\n",
    "            H = Lambda_matrix.copy()\n",
    "            for n in range(len(x)):\n",
    "                H += y[n] * (1 - y[n]) * (x[n].reshape(-1,1) @ x[n].reshape(1,-1))\n",
    "            \n",
    "            grad = Lambda_matrix @ w + x.T @ (y - t).reshape(-1,1) \n",
    "            \n",
    "            # calculate new w and its error\n",
    "            w = w - np.linalg.inv(H) @ grad # new w\n",
    "            w_list.append(w)\n",
    "            \n",
    "            cur_error = error_function(w) # current error\n",
    "            error.append(cur_error)\n",
    "            \n",
    "            # calculate the improvement on the error function\n",
    "            if (abs(cur_error - last_error) < self.tol):\n",
    "                break\n",
    "                \n",
    "            # stor the last error\n",
    "            last_error = cur_error\n",
    "            \n",
    "        # final result of w, error\n",
    "        min_index = error.index(min(error))\n",
    "        self.w = w_list[min_index]\n",
    "        self.error = min(error) # choose the smallest one to be error\n",
    "        \n",
    "        # if verbal = True, print w\n",
    "        if(verbal):\n",
    "            print(w)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"doing prediction\"\"\"\n",
    "        \n",
    "        # add intercept if add_intercept = True\n",
    "        if(self.add_intercept):\n",
    "            intercept = np.ones((x.shape[0], 1))\n",
    "            x = np.concatenate((x, intercept), axis = 1)\n",
    "            \n",
    "        # obtain the predicted prob of y\n",
    "        y = 1 / (1 + np.exp(-x @ self.w))\n",
    "        \n",
    "        # transform to 0 and 1; use 0.5 as the threshold for the positive case\n",
    "        t_pred = y.copy()\n",
    "        t_pred[y >= 0.5] = 1\n",
    "        t_pred[y < 0.5] = 0\n",
    "        \n",
    "        return t_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```計算 Accuracy```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(pred, actual = adult50kp['y_test']):\n",
    "    \"\"\"compute accuracy\"\"\"\n",
    "    ncorrect = np.sum(actual == pred)\n",
    "    accuracy = ncorrect / actual.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case1: \n",
    "\n",
    "$\\lambda = 1$ for all coefficients (no intercept in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec1 = create_lambda_vec(num_w = 1, bin_w = 1, add_intercept = False)\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec1, max_iter = 1000, tol = 1e-5, add_intercept = False)\n",
    "logic1.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "ypred1 = logic1.predict(adult50kp['x_test']).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Case 1】\n",
      "Weights:\n",
      "[[ 0.25829765  0.35286355  2.33421989  0.76093037  0.33328473  0.07921358\n",
      "  -0.419065   -0.20451831 -0.9629374  -1.33000522 -0.3288797   0.90975624\n",
      "  -0.82700342 -0.08741964 -0.4336111  -0.70534448 -0.28227076 -1.59439588\n",
      "  -0.74125351 -0.01306693  0.05205653  0.78777243 -0.99240259 -0.69494818\n",
      "  -0.27531241 -0.82656047 -1.65298178  0.50035667  0.5744047   0.27914971\n",
      "   0.64286175 -0.10294562 -0.05522086 -0.25465123 -0.20782379  0.59348693\n",
      "   0.40713026 -0.02200255 -0.00265095 -0.56924112 -0.27740542 -0.24561796\n",
      "  -0.10973204 -0.1785307  -0.18530458 -1.1801582   0.09228902 -0.14021619\n",
      "   0.95308764  0.43076916 -0.52328048 -1.29561267  0.45661075 -0.92159731\n",
      "  -0.08387461 -0.377851    0.40295961  0.56788744  0.5513525  -0.646118\n",
      "  -0.08193625  0.06989464 -0.15796955 -0.02724891  0.01354307 -0.31896669\n",
      "   0.12772484  0.4727378   0.8610213   0.12126426  0.31527274 -0.33233611\n",
      "  -0.3886933  -0.38430904 -0.67919585 -0.42890424  0.417121    0.10920407\n",
      "   0.11723865 -0.14731267 -0.07426403 -0.96113575 -0.05557072 -0.31865534\n",
      "  -0.16974509  0.31952357 -0.80987719  0.55779359  0.34408602 -0.34313169\n",
      "  -0.15401317  0.02252656 -0.64130566 -0.46470984 -1.09910162 -0.86643889\n",
      "   1.3235659   0.99914097 -0.81846027 -1.35692457 -0.94010275 -0.67642978]]\n",
      "Accuracy: 0.847808764940239\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"【Case 1】\")\n",
    "print(f\"Weights:\\n{logic1.w.reshape(1,-1)}\")\n",
    "print(f\"Accuracy: {cal_accuracy(ypred1)}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case2: \n",
    "\n",
    "$\\lambda = 1$ for all but the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec2 = create_lambda_vec(num_w = 1, bin_w = 1, add_intercept = True)\n",
    "logic2 = mylogistic_l2(reg_vec = lambda_vec2, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic2.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "ypred2 = logic2.predict(adult50kp['x_test']).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Case 2】\n",
      "Weights:\n",
      "[[ 0.25833063  0.35307341  2.33348255  0.7378757   0.33385106  0.07926886\n",
      "  -0.04219572  0.1998764  -0.58360968 -0.93671312  0.07548468  1.28715744\n",
      "  -0.37140327  0.39422898  0.04305748 -0.26147348  0.19559029 -0.42695771\n",
      "   0.42695771  0.16424528  0.22840772  0.96472553 -0.81743779 -0.52074423\n",
      "  -0.09910239 -0.64944042 -1.55235098  0.6786798   0.75066429  0.45541098\n",
      "   0.81857112  0.07308911  0.0728464  -0.11752644 -0.06282948  0.67242506\n",
      "   0.5040869   0.08799091  0.11435013 -0.38483984 -0.10196309 -0.05145374\n",
      "   0.10741777 -0.01997934  0.01717544 -1.16567808  0.30082277  0.02715464\n",
      "   1.00831207  0.50210397 -0.45756662 -1.24002555  0.52780939 -0.86832688\n",
      "  -0.02771494 -0.31412701  0.47343435  0.62981111  0.62405658 -0.5867506\n",
      "  -0.0296708   0.12414401 -0.14376238  0.02434194  0.0621604  -0.24843986\n",
      "   0.19459429  0.52620501  0.93165615  0.18707696  0.37950109 -0.28749402\n",
      "  -0.31137357 -0.33290534 -0.65117786 -0.38160106  0.48879121  0.17662205\n",
      "   0.17410342 -0.07343502 -0.0314651  -0.89846776  0.00653561 -0.27232555\n",
      "  -0.12442075  0.39697177 -0.75318727  0.61067658  0.70544004  0.01789988\n",
      "   0.2090388   0.382747   -0.2795817  -0.10453082 -0.9310132  -0.52642474\n",
      "   1.61398954  1.36735898 -0.49235221 -1.01493649 -0.60567591 -0.34195917\n",
      "  -3.17508577]]\n",
      "Accuracy: 0.8477423638778221\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"【Case 2】\")\n",
    "print(f\"Weights:\\n{logic2.w.reshape(1,-1)}\")\n",
    "print(f\"Accuracy: {cal_accuracy(ypred2)}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case3: \n",
    "\n",
    "$\\lambda = 1$ for all numerical-values features, $\\lambda = 0.5$ for binary-valued features, no regularization for intercept term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec3 = create_lambda_vec(num_w = 1, bin_w = 0.5, add_intercept = True)\n",
    "logic3 = mylogistic_l2(reg_vec = lambda_vec3, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic3.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "ypred3 = logic3.predict(adult50kp['x_test']).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Case 3】\n",
      "Weights:\n",
      "[[ 0.25851661  0.3533387   2.33562764  0.7825921   0.33439916  0.07940036\n",
      "  -0.08347988  0.23309134 -0.59278098 -0.9224849   0.11139573  1.25425869\n",
      "  -0.38299462  0.41291781  0.04136013 -0.26411462  0.19283128 -0.42890321\n",
      "   0.42890321  0.23635122  0.30021361  1.03810521 -0.75216086 -0.4534137\n",
      "  -0.02691157 -0.5825269  -2.00075382  0.75127891  0.82696617  0.52830705\n",
      "   0.89488994  0.14510375  0.18253094 -0.02583999  0.00991404  0.89862004\n",
      "   0.68517002  0.23294385  0.24519931 -0.38363083 -0.08029608 -0.06493444\n",
      "   0.0453608   0.03743376 -0.01295908 -2.09374319  0.25763304  0.06659781\n",
      "   1.18748312  0.55059265 -0.47576613 -1.45842154  0.5822242  -1.0627833\n",
      "  -0.00957211 -0.31704572  0.52485137  0.73044517  0.67457228 -0.63624179\n",
      "  -0.00967268  0.17339113 -0.2364757   0.0375474   0.10120874 -0.24679341\n",
      "   0.23800627  0.64228457  1.00567032  0.23258941  0.42267607 -0.35336167\n",
      "  -0.29178766 -0.38125401 -0.96291964 -0.45007954  0.512985    0.22019382\n",
      "   0.22640627 -0.04989103 -0.01836864 -0.95953334  0.01656804 -0.32741555\n",
      "  -0.14011404  0.42856024 -0.84476926  0.75121645  0.76670733  0.07638783\n",
      "   0.26824615  0.44314098 -0.2205815  -0.04631789 -1.28758289 -0.57187068\n",
      "   1.82502287  1.39622511 -0.54691696 -1.05894077 -0.65551468 -0.38800489\n",
      "  -3.36269033]]\n",
      "Accuracy: 0.847675962815405\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"【Case 3】\")\n",
    "print(f\"Weights:\\n{logic3.w.reshape(1,-1)}\")\n",
    "print(f\"Accuracy: {cal_accuracy(ypred3)}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```說明```\n",
    "\n",
    "Case 1: 這個模型不包含截距項, 另外所有變數之正規項係數皆為 1\n",
    "\n",
    "Case 2: 這個模型包含截距項, 另外除了截距項之正規項係數為 0 以外, 其餘皆為 1\n",
    "\n",
    "Case 3: 這個模型包含截距項, 另外截距項之正規項係數為 0, 連續變數為 1, 類別變數則是 0.5\n",
    "\n",
    "\n",
    "```結果討論```\n",
    "- 三者之準確度非常接近, 都落於 0.847 左右\n",
    "- 準確度排序: Case 1 > Case 2 > Case 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3\n",
    "將 training data 切割為 subtraining (90%) 還有 tuning (10%), 並依據題目給定的步驟, 尋找最佳的 hyperparameters。並且計算使用最佳超參數以後的模型準確率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```分割 training data ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random permutation dataset\n",
    "x = adult50kp['x_train']\n",
    "y = adult50kp['y_train']\n",
    "indices = np.random.permutation(x_train.shape[0])\n",
    "\n",
    "# split training data into subtraining and tuning\n",
    "split_len = int(len(x) * 0.9)\n",
    "sub_idx = indices[:split_len]\n",
    "tune_idx = indices[split_len:]\n",
    "\n",
    "# get x_subtrain, y_subtrain, x_tune, x_tune\n",
    "x_subtrain, y_subtrain, x_tune, y_tune = x[sub_idx], y[sub_idx], x[tune_idx], y[tune_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```進行 grid search```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constraint: a1 = a2\n",
    "\n",
    "accuracy_best = np.inf\n",
    "a_best = 0\n",
    "\n",
    "for a in np.linspace(start = 0.01, stop = 10, num = 10):\n",
    "    # train model and obtain accuracy\n",
    "    lambda_vec_a = create_lambda_vec(num_w = a, bin_w = a, add_intercept = True)\n",
    "    logic_a = mylogistic_l2(reg_vec = lambda_vec_a, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic_a.fit(x_subtrain, y_subtrain)\n",
    "    ypred_a = logic_a.predict(x_tune)\n",
    "    accuracy_a = cal_accuracy(ypred_a).reshape(1,-1)\n",
    "    \n",
    "    if(accuracy_a < accuracy_best):\n",
    "        accuracy_best = accuracy_a\n",
    "        a_best = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix a1 = a1*, search a2\n",
    "\n",
    "accuracy_best = np.inf\n",
    "a2_best = 0\n",
    "\n",
    "for a2 in np.linspace(start = 0.01, stop = 10, num = 10):\n",
    "    # train model and obtain accuracy\n",
    "    lambda_vec_a2 = create_lambda_vec(num_w = a_best, bin_w = a2, add_intercept = True)\n",
    "    logic_a2 = mylogistic_l2(reg_vec = lambda_vec_a2, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic_a2.fit(x_subtrain, y_subtrain)\n",
    "    ypred_a2 = logic_a.predict(x_tune)\n",
    "    accuracy_a2 = cal_accuracy(ypred_a2).reshape(1,-1)\n",
    "    \n",
    "    if(accuracy_a2 < accuracy_best):\n",
    "        accuracy_best = accuracy_a2\n",
    "        a2_best = a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix a2 = a2*, search a1\n",
    "\n",
    "accuracy_best = np.inf\n",
    "a1_best = 0\n",
    "\n",
    "for a1 in np.linspace(start = 0.01, stop = 10, num = 10):\n",
    "    # train model and obtain accuracy\n",
    "    lambda_vec_a1 = create_lambda_vec(num_w = a1, bin_w = a2_best, add_intercept = True)\n",
    "    logic_a1 = mylogistic_l2(reg_vec = lambda_vec_a1, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic_a1.fit(x_subtrain, y_subtrain)\n",
    "    ypred_a1 = logic_a.predict(x_tune).reshape(1,-1)\n",
    "    accuracy_a1 = cal_accuracy(ypred_a1)\n",
    "    \n",
    "    if(accuracy_a1 < accuracy_best):\n",
    "        accuracy_best = accuracy_a1\n",
    "        a1_best = a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1* = 0.01, a2 = 0.01\n"
     ]
    }
   ],
   "source": [
    "# report selected a1, a2\n",
    "print(f\"a1* = {a1_best}, a2 = {a2_best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 0.8476095617529881\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train a model, and report test accuracy\n",
    "lambda_vec_best = create_lambda_vec(num_w = a1_best, bin_w = a2_best, add_intercept = True)\n",
    "logic_best = mylogistic_l2(reg_vec = lambda_vec_best, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic_best.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "ypred_best = logic_best.predict(adult50kp['x_test']).reshape(1,-1)\n",
    "accuracy_final = cal_accuracy(ypred_best)\n",
    "print(f\"test accuracy = {accuracy_final}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```結果討論```\n",
    "- 最後選出的 a1, a2 皆為 0.01\n",
    "- 準確度和前面的模型也很接近。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.4\n",
    "本題欲利用 sklearn 套件訓練、測試模型, 另外也需要進行調整超參數的動作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.847808764940239\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid = {\"C\":np.logspace(-3,3,5), \"penalty\":[\"l1\",\"l2\"]}\n",
    "model = LogisticRegression()\n",
    "model_tune = GridSearchCV(model, grid, cv = 10)\n",
    "model_tune.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "\n",
    "accuracy = model_tune.score(adult50kp['x_test'], adult50kp['y_test'])\n",
    "print(f\"accuracy = {accuracy}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```說明```\n",
    "\n",
    "這邊有進行的超參數調整有正規化的強度 (C) 還有正規化的方式 (penalty)\n",
    "\n",
    "```結果討論```\n",
    "- 和前面的 case 之準確度都相當接近。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
